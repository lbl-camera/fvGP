{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46543b75",
   "metadata": {},
   "source": [
    "# Multi-Task Test\n",
    "At first we have to install the newest version of fvGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##first install the newest version of fvgp\n",
    "#!pip install fvgp~=4.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb622a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10dbfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fvgp import GP\n",
    "import plotly.graph_objects as go\n",
    "from itertools import product\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24b8ed",
   "metadata": {},
   "source": [
    "## Simple 1d Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3217ab",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x): return 0.5 * x\n",
    "def f2(x): return (-.25 * x) - 1.\n",
    "\n",
    "x_pred1d = np.linspace(0,1,50)\n",
    "plt.plot(x_pred1d,f1(x_pred1d))\n",
    "plt.plot(x_pred1d,f2(x_pred1d))\n",
    "x_data = np.random.rand(10)\n",
    "y_data1 = f1(x_data) + np.random.uniform(low = -0.01, high = 0.01, size =len(x_data))\n",
    "y_data2 = f2(x_data) + np.random.uniform(low = -0.01, high = 0.01, size =len(x_data))\n",
    "plt.scatter(x_data,y_data1) \n",
    "plt.scatter(x_data,y_data2) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17473590",
   "metadata": {},
   "source": [
    "### GP initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvgp import fvGP\n",
    "\n",
    "my_gp2 = fvGP(x_data.reshape(len(x_data),1), np.column_stack([y_data1, y_data2]), info = False)\n",
    "print(\"Global Training in progress\")\n",
    "my_gp2.train(max_iter = 20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8574f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_gp2.x_data)\n",
    "print(my_gp2.y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65197cd",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean and standard deviation\n",
    "mean = my_gp2.posterior_mean(x_pred=x_pred1d.reshape(50,1), x_out=np.array([0,1]))[\"f(x)\"]\n",
    "std = np.sqrt(my_gp2.posterior_covariance(x_pred=x_pred1d.reshape(50,1), x_out=np.array([0,1]))[\"v(x)\"])\n",
    "\n",
    "plt.plot(x_pred1d.reshape(50,1),mean[:,0], label = \"mean task 1\")\n",
    "plt.plot(x_pred1d.reshape(50,1),mean[:,1], label = \"mean task 2\")\n",
    "plt.scatter(x_data,y_data1) \n",
    "plt.scatter(x_data,y_data2) \n",
    "plt.plot(x_pred1d,f1(x_pred1d), label = \"task 1 ground truth\")\n",
    "plt.plot(x_pred1d,f2(x_pred1d), label = \"task 2 ground truth\")\n",
    "plt.fill_between(x_pred1d, mean[:,0] - 3. * std[:,0], mean[:,0] + 3. * std[:,0], alpha = 0.5, color = \"grey\")\n",
    "plt.fill_between(x_pred1d, mean[:,1] - 3. * std[:,1], mean[:,1] + 3. * std[:,1], alpha = 0.5, color = \"grey\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596cd1c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#mean gradient and variance gradient\n",
    "mean_grad = my_gp2.posterior_mean_grad(x_pred=x_pred1d.reshape(50,1), x_out=np.array([0,1]))[\"df/dx\"]\n",
    "var_grad = my_gp2.posterior_covariance_grad(x_pred=x_pred1d.reshape(50,1), x_out=np.array([0,1]))[\"dv/dx\"]\n",
    "\n",
    "plt.plot(x_pred1d.reshape(50,1),mean_grad[:,0,0], label = \"mean gradient task 1\")\n",
    "plt.plot(x_pred1d.reshape(50,1),mean_grad[:,0,1], label = \"mean gradient task 2\")\n",
    "plt.plot(x_pred1d,np.gradient(f1(x_pred1d), 1./50.), label = \"grad task 1 ground truth\")\n",
    "plt.plot(x_pred1d,np.gradient(f2(x_pred1d), 1./50.), label = \"grad task 2 ground truth\")\n",
    "plt.plot(x_pred1d.reshape(50,1),var_grad[:,0,0], label = \"var gradient task 1\")\n",
    "plt.plot(x_pred1d.reshape(50,1),var_grad[:,0,1], label = \"var gradient task 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13fb64",
   "metadata": {},
   "source": [
    "### What if some tasks are missing from the data\n",
    "\n",
    "#### It works just fine, but we have to let the algorithm know by communicating data lists without the missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list  = []\n",
    "output_pos = []\n",
    "for i in range(len(y_data1)):\n",
    "    if np.random.rand() < .2:\n",
    "        y_list.append([y_data1[i]])\n",
    "        output_pos.append([0])\n",
    "    else:\n",
    "        y_list.append([y_data1[i], y_data2[i]])\n",
    "        output_pos.append([0,1])\n",
    "    print(y_list[-1], output_pos[-1])\n",
    "\n",
    "\n",
    "my_gp2 = fvGP(x_data.reshape(len(x_data),1), y_list, output_positions=output_pos, info = False)\n",
    "print(\"Global Training in progress\")\n",
    "my_gp2.train(max_iter = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32340c12",
   "metadata": {},
   "source": [
    "## 3d Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641bbb64",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d533642",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./data/sim_variable_mod.npy\")\n",
    "sparsification = 32\n",
    "\n",
    "x_data3 = data[:,5:][::sparsification]\n",
    "y_data3 = data[:,0:3][::sparsification]\n",
    "\n",
    "#it is good practice to check the format of the data\n",
    "print(x_data3.shape)\n",
    "print(y_data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653de33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(30,100,100)\n",
    "y = np.linspace(40,130,100)\n",
    "x_pred3D = np.asarray(list(product(x, y)))\n",
    "x_pred3D = np.column_stack([x_pred3D, np.zeros((len(x_pred3D),1)) + 300.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd4c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(x,y,z,size=3, color = 1):\n",
    "    #if not color: color = z\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter3d(x=x, y=y, z=z,mode='markers',marker=dict(color=color, size = size)))\n",
    "    \n",
    "    \n",
    "    fig.update_layout(autosize=False,\n",
    "                  width=800, height=800,\n",
    "                  font=dict(size=18,),\n",
    "                  margin=dict(l=0, r=0, b=0, t=0))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1b61c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scatter(x_data3[:,0],x_data3[:,1],x_data3[:,2], size = 5, color = y_data3[:,0])\n",
    "scatter(x_data3[:,0],x_data3[:,1],x_data3[:,2], size = 5, color = y_data3[:,1])\n",
    "scatter(x_data3[:,0],x_data3[:,1],x_data3[:,2], size = 5, color = y_data3[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e008acb",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fae406",
   "metadata": {},
   "source": [
    "#### (a) Default behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01029897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvgp import fvGP\n",
    "\n",
    "my_gp2 = fvGP(x_data3,y_data3, info = False)\n",
    "print(\"Global Training in progress\")\n",
    "my_gp2.train(max_iter = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb81468b",
   "metadata": {},
   "source": [
    "#### (b) Custom kernel\n",
    "It is vital in the multi-task case to think hard about kernel design. The kernel is now a function\n",
    "over X x X x T x T, where X is the input and T is the output space. Print the input of the kernel, it will have the dimensionality of this cartesian product space. \n",
    "The default kernel in fvgp is just a Matern kernel operating in this new space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a0dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A simple kernel, that won't lead to good performance because it's stationary\n",
    "from fvgp.gp_kernels import *\n",
    "def mkernel(x1,x2,hps):\n",
    "    d = get_distance_matrix(x1,x2)\n",
    "    return hps[0] * matern_kernel_diff1(d,hps[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e082b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gp2 = fvGP(x_data3,y_data3, info = False,\n",
    "              init_hyperparameters=np.ones((2)), gp_kernel_function=mkernel\n",
    "             )\n",
    "print(\"Global Training in progress\")\n",
    "\n",
    "\n",
    "bounds = np.array([[0.01,1.],[0.01,1.]])\n",
    "my_gp2.train(hyperparameter_bounds=bounds,max_iter = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d2dc0",
   "metadata": {},
   "source": [
    "#### (c) A custom deep kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef1c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvgp.deep_kernel_network import *\n",
    "iset_dim = 4\n",
    "gp_deep_kernel_layer_width = 5\n",
    "n = Network(iset_dim, gp_deep_kernel_layer_width)\n",
    "print(n.number_of_hps)\n",
    "\n",
    "def deep_multi_task_kernel(x1, x2, hps):  # pragma: no cover\n",
    "    signal_var = hps[0]\n",
    "    length_scale = hps[1]\n",
    "    hps_nn = hps[2:]\n",
    "    w1_indices = np.arange(0, gp_deep_kernel_layer_width * iset_dim)\n",
    "    last = gp_deep_kernel_layer_width * iset_dim\n",
    "    w2_indices = np.arange(last, last + gp_deep_kernel_layer_width ** 2)\n",
    "    last = last + gp_deep_kernel_layer_width ** 2\n",
    "    w3_indices = np.arange(last, last + gp_deep_kernel_layer_width * iset_dim)\n",
    "    last = last + gp_deep_kernel_layer_width * iset_dim\n",
    "    b1_indices = np.arange(last, last + gp_deep_kernel_layer_width)\n",
    "    last = last + gp_deep_kernel_layer_width\n",
    "    b2_indices = np.arange(last, last + gp_deep_kernel_layer_width)\n",
    "    last = last + gp_deep_kernel_layer_width\n",
    "    b3_indices = np.arange(last, last + iset_dim)\n",
    "\n",
    "    n.set_weights(hps_nn[w1_indices].reshape(gp_deep_kernel_layer_width, iset_dim),\n",
    "                  hps_nn[w2_indices].reshape(gp_deep_kernel_layer_width, gp_deep_kernel_layer_width),\n",
    "                  hps_nn[w3_indices].reshape(iset_dim, gp_deep_kernel_layer_width))\n",
    "    n.set_biases(hps_nn[b1_indices].reshape(gp_deep_kernel_layer_width),\n",
    "                 hps_nn[b2_indices].reshape(gp_deep_kernel_layer_width),\n",
    "                 hps_nn[b3_indices].reshape(iset_dim))\n",
    "    x1_nn = n.forward(x1)\n",
    "    x2_nn = n.forward(x2)\n",
    "    d = get_distance_matrix(x1_nn, x2_nn)\n",
    "    k = signal_var * matern_kernel_diff1(d, length_scale)\n",
    "    return k\n",
    "\n",
    "\n",
    "my_gp2 = fvGP(x_data3,y_data3, info = False,\n",
    "              init_hyperparameters=np.ones((n.number_of_hps+2)), gp_kernel_function=deep_multi_task_kernel\n",
    "             )\n",
    "print(\"Global Training in progress\")\n",
    "\n",
    "\n",
    "bounds = np.zeros((n.number_of_hps+2,2))\n",
    "bounds[0] = np.array([0.001,10.])\n",
    "bounds[1] = np.array([0.001,10.])\n",
    "bounds[2:] = np.array([-1,1])\n",
    "my_gp2.train(hyperparameter_bounds=bounds,max_iter = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f4602",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first task\n",
    "mean1 = my_gp2.posterior_mean(x_pred3D, x_out = np.zeros((1)))[\"f(x)\"]\n",
    "var1 =  my_gp2.posterior_covariance(x_pred3D, x_out = np.zeros((1)))[\"v(x)\"]\n",
    "\n",
    "#second task\n",
    "mean2 = my_gp2.posterior_mean(x_pred3D, x_out = np.zeros((1)) + 1)[\"f(x)\"]\n",
    "var2 =  my_gp2.posterior_covariance(x_pred3D, x_out = np.zeros((1))+1)[\"v(x)\"]\n",
    "\n",
    "#third task\n",
    "mean3 = my_gp2.posterior_mean(x_pred3D, x_out = np.zeros((1)) + 2)[\"f(x)\"]\n",
    "var3 =  my_gp2.posterior_covariance(x_pred3D, x_out = np.zeros((1))+2)[\"v(x)\"]\n",
    "\n",
    "##we could have also called for all tasks\n",
    "#mean = my_gp2.posterior_mean(x_pred3D, x_out = np.array([0,1,2]))[\"f(x)\"]\n",
    "#var =  my_gp2.posterior_covariance(x_pred3D, x_out = np.array([0,1,2]))[\"v(x)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4396abe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#extract data point to compare to:\n",
    "index300 = np.where(x_data3[:,2]==300.)\n",
    "imageX_data = x_data3[index300]\n",
    "imageY_data = y_data3[index300]\n",
    "#print(y_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95443139",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter3d(x=x_pred3D[:,0],y=x_pred3D[:,1], z=mean1,\n",
    "                             mode='markers',marker=dict(color=mean1, size = 5)))\n",
    "fig.add_trace(go.Scatter3d(x=imageX_data[:,0], y=imageX_data[:,1] , z=imageY_data[:,0],\n",
    "                           mode='markers',marker=dict(color=imageY_data[:,0], size = 5)))\n",
    "fig.update_layout(autosize=False,\n",
    "                  width=800, height=800,\n",
    "                  font=dict(size=18,),\n",
    "                  margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter3d(x=x_pred3D[:,0], y=x_pred3D[:,1], z=mean2,\n",
    "                           mode='markers',marker=dict(color=mean2, size = 5)))\n",
    "fig.add_trace(go.Scatter3d(x=imageX_data[:,0], y=imageX_data[:,1], z=imageY_data[:,1],\n",
    "                           mode='markers',marker=dict(color=imageY_data[:,1], size = 5)))\n",
    "fig.update_layout(autosize=False,\n",
    "                  width=800, height=800,\n",
    "                  font=dict(size=18,),\n",
    "                  margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter3d(x=x_pred3D[:,0], y=x_pred3D[:,1], z=mean3,\n",
    "                           mode='markers',marker=dict(color=mean3, size = 5)))\n",
    "fig.add_trace(go.Scatter3d(x=imageX_data[:,0], y=imageX_data[:,1], z=imageY_data[:,2],\n",
    "                           mode='markers',marker=dict(color=imageY_data[:,2], size = 5)))\n",
    "fig.update_layout(autosize=False,\n",
    "                  width=800, height=800,\n",
    "                  font=dict(size=18,),\n",
    "                  margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
