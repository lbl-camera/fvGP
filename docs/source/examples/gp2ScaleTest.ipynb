{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f741cc98",
   "metadata": {},
   "source": [
    "# gp2Scale \n",
    "gp2Scale is a special setting in fvgp that combines non-stationary, compactly-supported kernels, HPC distributed computing, and sparse linear algebra to allow scale-up of exact GPs to millions of data points. gp2Scale holds the world record in this category! Here we run a moderately-sized GP, just because we assume you might run this locally.\n",
    "\n",
    "I hope it is clear how cool it is what is happening here. If you have a dask client that points to a remote cluster with 500 GPUs, you will distribute the covariance matrix computation across those. The full matrix is sparse and will be fast to work with in downstream operations. The algorithm only makes use of naturally-occuring sparsity, so the result is exact in contrast to Vecchia or inducing-point methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91463be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##first install the newest version of fvgp\n",
    "#!pip install fvgp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8db0f9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f157c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fvgp import GP\n",
    "from dask.distributed import Client\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "client = Client() ##this is the client you can make locally like this or \n",
    "#your HPC team can provide a script to get it. We included an example to get gp2Scale going\n",
    "#on Perlmutter\n",
    "\n",
    "\n",
    "#It's good practice to make sure to wait for all the workers to be ready\n",
    "client.wait_for_workers(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d8d03f",
   "metadata": {},
   "source": [
    "## Preparing the data and some other inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ebb782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    return ((np.sin(5. * x) + np.cos(10. * x) + (2.* (x-0.4)**2) * np.cos(100. * x)))\n",
    "\n",
    "input_dim = 1\n",
    "N = 5532\n",
    "x_data = np.random.rand(N,input_dim)\n",
    "y_data = f1(x_data).reshape(len(x_data))\n",
    "hps_n = 2\n",
    "\n",
    "hps_bounds = np.array([[0.1,1.],      ##signal var of Wendland kernel\n",
    "                       [0.001,0.04]])  ##length scale for Wendland kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec159f5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_hps = np.random.uniform(size = len(hps_bounds), low = hps_bounds[:,0], high = hps_bounds[:,1])\n",
    "from fvgp.gp_kernels import wendland_anisotropic_gp2Scale_cpu\n",
    "def kernel(x1,x2,hps,obj):\n",
    "    return wendland_anisotropic_gp2Scale_cpu(x1,x2,hps,obj)\n",
    "\n",
    "\n",
    "\n",
    "my_gp2S = GP(x_data,y_data, gp_kernel_function=kernel, init_hyperparameters = init_hps, #compute_device = 'gpu', #you can use gpus here\n",
    "            gp2Scale = True, gp2Scale_batch_size= 1000, gp2Scale_dask_client = client, info = True\n",
    "            )\n",
    "\n",
    "my_gp2S.train(hyperparameter_bounds = hps_bounds, max_iter = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eebd186",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_gp2S.get_hyperparameters())\n",
    "print(my_gp2S.log_likelihood(my_gp2S.get_hyperparameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10489588",
   "metadata": {},
   "source": [
    "## Posterior evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e48897",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.linspace(0,1,100) ##for big GPs, this is usually not a good idea, but in 1d, we can still do it\n",
    "                              ##It's better to do predictions only for a handful of points at a time.\n",
    "\n",
    "mean1 = my_gp2S.posterior_mean(x_pred.reshape(-1,1))[\"f(x)\"]\n",
    "var1 =  my_gp2S.posterior_covariance(x_pred.reshape(-1,1), variance_only=False)[\"v(x)\"]\n",
    "\n",
    "print(my_gp2S.get_hyperparameters())\n",
    "\n",
    "plt.figure(figsize = (16,10))\n",
    "plt.plot(x_pred,mean1, label = \"posterior mean\", linewidth = 4)\n",
    "plt.plot(x_pred,f1(x_pred), label = \"latent function\", linewidth = 4)\n",
    "plt.fill_between(x_pred, mean1 - 3. * np.sqrt(var1), mean1 + 3. * np.sqrt(var1), alpha = 0.5, color = \"grey\", label = \"var\")\n",
    "plt.scatter(x_data,y_data, color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f4b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
